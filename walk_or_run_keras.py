# -*- coding: utf-8 -*-
"""Walk or Run Keras.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LY6E8BfKhiynpWiOmW_rICQQjr9E9jSW
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install -q keras

from __future__ import print_function
import keras
from keras.models import load_model
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras. layers import Conv2D, MaxPooling2D
from keras import backend as K

import matplotlib.pyplot as plt


import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

import cv2         # For image
from random import shuffle #For shuffling our data cause 
#other way it might be take always run or walk datas to training

from tqdm import tqdm

import os
        
TRAIN_DIR_RUN = "/content/drive/My Drive/Deep learning projeleri/Walk or Run/Data/train/run"
TRAIN_DIR_WALK = "/content/drive/My Drive/Deep learning projeleri/Walk or Run/Data/train/walk"
TEST_DIR_RUN = "/content/drive/My Drive/Deep learning projeleri/Walk or Run/Data/test/run"
TEST_DIR_WALK = "/content/drive/My Drive/Deep learning projeleri/Walk or Run/Data/test/walk"

IMG_SIZE = 100

"""
from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img
 
datagen = ImageDataGenerator(rotation_range=180,
                             width_shift_range=0.2,
                             height_shift_range=0.2,
                             shear_range=0.2,
                             horizontal_flip=True,
                             vertical_flip=True,
                             fill_mode='nearest')


for img in tqdm(os.listdir(TRAIN_DIR_RUN)):
        path = os.path.join(TRAIN_DIR_RUN,img)#here we are giving the path
        img = load_img(path)#reading as a grayscale
        x = img_to_array(img)
        x = x.reshape((1,)+ x.shape)
        i = 0

        for batch in datagen.flow(x, batch_size=1,
                          save_to_dir='/content/drive/My Drive/Deep learning projeleri/Walk or Run/Data/train/run', 
                          save_format='png'):
            i += 1
            if i > 7:
                break
  
for img in tqdm(os.listdir(TRAIN_DIR_WALK)):
        path = os.path.join(TRAIN_DIR_WALK,img)#here we are giving the path
        img = load_img(path)#reading as a grayscale
        x = img_to_array(img)
        x = x.reshape((1,)+ x.shape)
        i = 0

        for batch in datagen.flow(x, batch_size=1,
                          save_to_dir='/content/drive/My Drive/Deep learning projeleri/Walk or Run/Data/train/walk', 
                          save_format='png'):
            i += 1
            if i > 7:
                break"""

#run = [0,1], walk = [1,0]
def create_train_data():
    training_data = []
    for img in tqdm(os.listdir(TRAIN_DIR_RUN)):
        path = os.path.join(TRAIN_DIR_RUN,img)#here we are giving the path
        img = cv2.imread(path,cv2.IMREAD_GRAYSCALE)#reading as a grayscale
        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))#image size
        training_data.append([np.array(img),np.array([0,1])])# image data, run or walk
        
    for img in tqdm(os.listdir(TRAIN_DIR_WALK)):
        path = os.path.join(TRAIN_DIR_WALK,img)
        img = cv2.imread(path,cv2.IMREAD_GRAYSCALE)
        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))
        training_data.append([np.array(img),np.array([1,0])])
    
    shuffle(training_data)
    return training_data

def create_test_data():
    testing_data = []
    for img in tqdm(os.listdir(TEST_DIR_RUN)):
        path = os.path.join(TEST_DIR_RUN, img)
        img_num = img.split('.')[0]#for taking id of the image (you may need to look the data)
        img_num = img_num.split('_')[1]#for same things
        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)
        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))
        testing_data.append([np.array(img), img_num])#image data, image id
        
    for img in tqdm(os.listdir(TEST_DIR_WALK)):
        path = os.path.join(TEST_DIR_WALK, img)
        img_num = img.split('.')[0]
        img_num = img_num.split('_')[1]
        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)
        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))
        testing_data.append([np.array(img), img_num])
    
    shuffle(testing_data)
    return testing_data

train_data = create_train_data()

train = train_data[100:]
test = train_data[:100]

print(len(train))
len(test)

batch_size = 64
num_classes = 2 
IMG_SIZE = 100

x_train = np.array([i[0] for i in train]).reshape(-1,IMG_SIZE,IMG_SIZE,1)
y_train = np.array([i[1] for i in train])

x_test = np.array([i[0] for i in test]).reshape(-1,IMG_SIZE,IMG_SIZE,1)
y_test = np.array([i[1] for i in test])

input_shape = (IMG_SIZE, IMG_SIZE, 1)

"""batch_size = 128 
num_classes = 2 
epochs = 20 
IMG_SIZE = 100

if K.image_data_format() == 'channels_first':
    x_train = x_train.reshape(x_train.shape[0], 1, IMG_SIZE, IMG_SIZE)
    x_test = x_test.reshape(x_test.shape[0], 1, IMG_SIZE, IMG_SIZE)
    input_shape = (1, IMG_SIZE, IMG_SIZE)
else:
    x_train = x_train.reshape(x_train.shape[0], IMG_SIZE, IMG_SIZE, 1)
    x_test = x_test.reshape(x_test.shape[0], IMG_SIZE, IMG_SIZE, 1)
    input_shape = (IMG_SIZE, IMG_SIZE, 1)

y_train = keras.utils.to_categorical(y_train, num_classes)
y_test = keras.utils.to_categorical(y_test, num_classes)
"""

model = Sequential()

model.add(Conv2D(32, kernel_size=(5, 5), strides=(1, 1),
                 padding='same',
                 activation='relu',
                 input_shape=input_shape))



model.add(Conv2D(64, (5, 5), strides=(1, 1), padding='same', activation='relu'))

model.add(Dropout(0.2))

model.add(Conv2D(32, (5, 5), strides=(2, 2), padding='same', activation='relu'))
model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same'))

model.add(Dropout(0.5))

model.add(Conv2D(64, (5, 5), strides=(2, 2), padding='same', activation='relu'))


model.add(Conv2D(64, (5, 5), strides=(2, 2), padding='same', activation='relu'))
model.add(Dropout(0.2))

model.add(Conv2D(64, (5, 5), strides=(2, 2), padding='same', activation='relu'))
model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same'))

model.add(Dense(1024, activation='relu'))

model.add(Flatten())

model.add(Dropout(0.8))

model.add(Dense(num_classes, activation='softmax'))

model.summary()

opt = keras.optimizers.Adam(learning_rate=0.001)
model.compile(loss = keras.losses.categorical_crossentropy,
             optimizer = keras.optimizers.Adadelta(),
             metrics = ['accuracy'])

epochs = 25
model.fit(x_train, y_train,
          batch_size=batch_size,
          epochs=epochs,
          verbose=1,
          validation_data=(x_test, y_test))

score = model.evaluate(x_test, y_test, verbose=0)
print('Test Loss:', score[0])
print('Test Accuracy:', score[1])

x_test.shape

test_data = create_test_data()

def img_data_data(x):
    for img in os.listdir(TEST_DIR_RUN):
        path = os.path.join(TEST_DIR_RUN, img)
        img_num = img.split('.')[0]
        img_num = img_num.split('_')[1]
        
        if img_num == x:
            imgUMat = cv2.imread(path)
            data = cv2.cvtColor(imgUMat, cv2.COLOR_BGR2RGB)
        
        
    for img in os.listdir(TEST_DIR_WALK):
        path = os.path.join(TEST_DIR_WALK, img)
        img_num = img.split('.')[0]
        img_num = img_num.split('_')[1]
        
        if img_num == x:
            imgUMat = cv2.imread(path)
            data = cv2.cvtColor(imgUMat, cv2.COLOR_BGR2RGB)
                
    return data

def img_plt(x):
    fig=plt.figure(figsize=(50,20))

    for i in range(len(img_numbers)):
    
        y = fig.add_subplot(4,5,i+1)
        orig = img_data_data(img_numbers[i])
        
        y.imshow(orig)
        plt.title(x[i], fontsize=18)
        y.axes.get_xaxis().set_visible(False)
        y.axes.get_yaxis().set_visible(False)
    
    plt.show()

img_numbers = []
str_label = []
for data in (test_data[:20]):
    img_numbers.append(data[1])
    
    img_data = data[0]
    img_data = img_data.reshape(1,IMG_SIZE,IMG_SIZE,1)
    
    model_out =  model.predict_classes([img_data])[0]
    print(model_out)
    print(model.predict([img_data]))
    
    if model_out == 1: str_label.append('Run')
    else: str_label.append('Walk')
    
img_plt(str_label)